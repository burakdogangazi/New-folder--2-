{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66ed2994",
   "metadata": {},
   "source": [
    "## 1. Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82bd9775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Standard Library\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Third-Party Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Scikit-Learn - Model Selection\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold\n",
    "\n",
    "# Scikit-Learn - Classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Scikit-Learn - Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# Visualization Settings\n",
    "sns.set(style=\"whitegrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Define paths for input and output\n",
    "FEATURE_PATH = os.path.join(\"data\", \"features\", \"combined_engineered_features.csv\")\n",
    "MODELS_DIR = os.path.join(\"data\", \"models\")\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "\n",
    "# Configuration\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d4096c",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab684283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (685671, 45)\n",
      "\n",
      "Attack traffic records: 284999\n",
      "Percentage of attack traffic: 41.56%\n",
      "\n",
      "============================================================\n",
      "Attack Type Distribution (Label2)\n",
      "============================================================\n",
      "label2\n",
      "recon         105848\n",
      "dos            57736\n",
      "ddos           56692\n",
      "mitm           25490\n",
      "malware        24177\n",
      "web             9040\n",
      "bruteforce      6016\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of attack classes: 7\n",
      "\n",
      "Feature matrix shape: (284999, 40)\n",
      "Target variable shape: (284999,)\n",
      "\n",
      "Class distribution:\n",
      "label2\n",
      "recon         105848\n",
      "dos            57736\n",
      "ddos           56692\n",
      "mitm           25490\n",
      "malware        24177\n",
      "web             9040\n",
      "bruteforce      6016\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the feature-engineered dataset\n",
    "df = pd.read_csv(FEATURE_PATH)\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "\n",
    "# Validate presence of required label columns\n",
    "assert \"label1\" in df.columns, \"label1 column not found in dataset\"\n",
    "assert \"label2\" in df.columns, \"label2 column not found in dataset\"\n",
    "\n",
    "# Filter to retain only attack traffic (exclude benign)\n",
    "df_attacks = df[df[\"label1\"].str.lower() == \"attack\"].copy()\n",
    "print(f\"\\nAttack traffic records: {df_attacks.shape[0]}\")\n",
    "print(f\"Percentage of attack traffic: {(df_attacks.shape[0] / df.shape[0] * 100):.2f}%\")\n",
    "\n",
    "# Analyze attack type distribution\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Attack Type Distribution (Label2)\")\n",
    "print(f\"{'='*60}\")\n",
    "print(df_attacks[\"label2\"].value_counts())\n",
    "print(f\"\\nNumber of attack classes: {df_attacks['label2'].nunique()}\")\n",
    "\n",
    "# Extract features and create multiclass target variable\n",
    "# Target: label2 (attack sub-types)\n",
    "X = df_attacks.drop(columns=[\"label1\", \"label2\", \"label3\", \"label4\", \"label_full\"], errors='ignore')\n",
    "y = df_attacks[\"label2\"].copy()\n",
    "\n",
    "print(f\"\\nFeature matrix shape: {X.shape}\")\n",
    "print(f\"Target variable shape: {y.shape}\")\n",
    "print(f\"\\nClass distribution:\\n{y.value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8fd5ba",
   "metadata": {},
   "source": [
    "## 3. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d959d4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (227999, 40)\n",
      "Test set shape: (57000, 40)\n",
      "\n",
      "Training set class distribution:\n",
      "label2\n",
      "recon         84678\n",
      "dos           46189\n",
      "ddos          45353\n",
      "mitm          20392\n",
      "malware       19342\n",
      "web            7232\n",
      "bruteforce     4813\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Perform stratified train-test split to maintain class distribution\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "print(f\"\\nTraining set class distribution:\\n{y_train.value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e33e9b0",
   "metadata": {},
   "source": [
    "## 4. Metrics Computation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad41b253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_multiclass(y_true, y_pred, y_prob=None):\n",
    "    \"\"\"\n",
    "    Compute comprehensive multiclass classification metrics.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_true : array-like\n",
    "        True labels\n",
    "    y_pred : array-like\n",
    "        Predicted labels\n",
    "    y_prob : array-like, optional\n",
    "        Predicted probabilities\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary containing computed multiclass metrics\n",
    "    \"\"\"\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec_macro = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    rec_macro = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    f1_weighted = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision_macro\": prec_macro,\n",
    "        \"recall_macro\": rec_macro,\n",
    "        \"f1_macro\": f1_macro,\n",
    "        \"f1_weighted\": f1_weighted,\n",
    "        \"confusion_matrix\": cm\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75334acb",
   "metadata": {},
   "source": [
    "## 5. Model Definition and Hyperparameter Grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0752bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models to train: ['log_reg', 'rf', 'lgb', 'mlp', 'knn', 'nb']\n",
      "Optimization method: RandomizedSearchCV\n",
      "Cross-validation folds: 3\n",
      "Iterations per model: 10\n",
      "Total models: 6\n"
     ]
    }
   ],
   "source": [
    "model_defs = {}\n",
    "\n",
    "# ============================================================================\n",
    "# LINEAR MODELS\n",
    "# ============================================================================\n",
    "\n",
    "# Logistic Regression - Fast baseline linear classifier\n",
    "model_defs[\"log_reg\"] = {\n",
    "    \"estimator\": LogisticRegression(max_iter=5000, random_state=RANDOM_STATE),\n",
    "    \"param_grid\": {\n",
    "        \"penalty\": [\"l2\"],\n",
    "        \"C\": [0.1, 1, 10, 100],\n",
    "        \"solver\": [\"lbfgs\", \"saga\"],\n",
    "        \"class_weight\": [None, \"balanced\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# TREE-BASED MODELS\n",
    "# ============================================================================\n",
    "\n",
    "# Random Forest - Ensemble of decision trees\n",
    "model_defs[\"rf\"] = {\n",
    "    \"estimator\": RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1),\n",
    "    \"param_grid\": {\n",
    "        \"n_estimators\": [50, 100, 200],\n",
    "        \"max_depth\": [10, 20, 30, None],\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"min_samples_leaf\": [1, 2, 4],\n",
    "        \"max_features\": [\"sqrt\"],\n",
    "        \"class_weight\": [None, \"balanced\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# LightGBM - Fast gradient boosting classifier\n",
    "model_defs[\"lgb\"] = {\n",
    "    \"estimator\": lgb.LGBMClassifier(\n",
    "        random_state=RANDOM_STATE, \n",
    "        n_jobs=-1, \n",
    "        verbose=-1,\n",
    "        is_unbalance=True\n",
    "    ),\n",
    "    \"param_grid\": {\n",
    "        \"n_estimators\": [100, 200, 300],\n",
    "        \"max_depth\": [5, 10, 15, -1],\n",
    "        \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "        \"num_leaves\": [20, 30, 40, 50],\n",
    "        \"min_data_in_leaf\": [10, 20, 30],\n",
    "        \"feature_fraction\": [0.8, 0.9, 1.0],\n",
    "        \"bagging_fraction\": [0.8, 0.9, 1.0]\n",
    "    }\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# NEURAL NETWORK MODELS\n",
    "# ============================================================================\n",
    "\n",
    "# Multi-Layer Perceptron - Neural network classifier\n",
    "model_defs[\"mlp\"] = {\n",
    "    \"estimator\": MLPClassifier(random_state=RANDOM_STATE, max_iter=500, early_stopping=False),\n",
    "    \"param_grid\": {\n",
    "        \"hidden_layer_sizes\": [(64,), (128,), (64, 32), (128, 64)],\n",
    "        \"activation\": [\"relu\", \"tanh\"],\n",
    "        \"alpha\": [0.0001, 0.001, 0.01],\n",
    "        \"learning_rate\": [\"constant\", \"adaptive\"],\n",
    "        \"batch_size\": [32, 64]\n",
    "    }\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# DISTANCE-BASED & PROBABILISTIC MODELS\n",
    "# ============================================================================\n",
    "\n",
    "# K-Nearest Neighbors - Distance-based instance classifier\n",
    "model_defs[\"knn\"] = {\n",
    "    \"estimator\": KNeighborsClassifier(),\n",
    "    \"param_grid\": {\n",
    "        \"n_neighbors\": [3, 5, 7, 9, 11],\n",
    "        \"weights\": [\"uniform\", \"distance\"],\n",
    "        \"metric\": [\"euclidean\", \"manhattan\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Gaussian Naive Bayes - Probabilistic classifier\n",
    "model_defs[\"nb\"] = {\n",
    "    \"estimator\": GaussianNB(),\n",
    "    \"param_grid\": {\n",
    "        \"var_smoothing\": np.logspace(-10, -6, 5)\n",
    "    }\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL TRAINING CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "MODELS_TO_RUN = [\"log_reg\", \"rf\", \"lgb\", \"mlp\", \"knn\", \"nb\"]\n",
    "\n",
    "print(f\"Models to train: {MODELS_TO_RUN}\")\n",
    "print(f\"Optimization method: RandomizedSearchCV\")\n",
    "print(f\"Cross-validation folds: 3\")\n",
    "print(f\"Iterations per model: 10\")\n",
    "print(f\"Total models: {len(MODELS_TO_RUN)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d857dba5",
   "metadata": {},
   "source": [
    "## 6. Model Training and Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "618462bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model_key, model_def, X_train, X_test, y_train, y_test,\n",
    "                             base_dir, cv_folds=3, n_iter=10, class_labels=None):\n",
    "    \"\"\"\n",
    "    Train a multiclass model using RandomizedSearchCV and evaluate on test set.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model_key : str\n",
    "        Model identifier\n",
    "    model_def : dict\n",
    "        Dictionary containing estimator and parameter grid\n",
    "    X_train, X_test : array-like\n",
    "        Training and test feature matrices\n",
    "    y_train, y_test : array-like\n",
    "        Training and test labels\n",
    "    base_dir : str\n",
    "        Base directory for saving results\n",
    "    cv_folds : int\n",
    "        Number of cross-validation folds\n",
    "    n_iter : int\n",
    "        Number of RandomizedSearchCV iterations\n",
    "    class_labels : list\n",
    "        List of class labels for visualization\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple : (results_dict, best_model, predictions, metrics)\n",
    "    \"\"\"\n",
    "    estimator = model_def[\"estimator\"]\n",
    "    param_grid = model_def[\"param_grid\"]\n",
    "\n",
    "    MODEL_DIR = os.path.join(base_dir, model_key)\n",
    "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {model_key.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # Perform hyperparameter tuning using RandomizedSearchCV\n",
    "    if param_grid:\n",
    "        cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=RANDOM_STATE)\n",
    "        search = RandomizedSearchCV(\n",
    "            estimator,\n",
    "            param_distributions=param_grid,\n",
    "            n_iter=n_iter,\n",
    "            scoring=\"f1_macro\",\n",
    "            cv=cv,\n",
    "            n_jobs=-1,\n",
    "            random_state=RANDOM_STATE,\n",
    "            verbose=1\n",
    "        )\n",
    "        search.fit(X_train, y_train)\n",
    "        best_model = search.best_estimator_\n",
    "        best_params = search.best_params_\n",
    "        cv_f1 = search.best_score_\n",
    "    else:\n",
    "        best_model = estimator\n",
    "        best_model.fit(X_train, y_train)\n",
    "        best_params = {}\n",
    "        cv_f1 = np.nan\n",
    "\n",
    "    print(f\"Best parameters: {best_params}\")\n",
    "    if not np.isnan(cv_f1):\n",
    "        print(f\"Cross-validation F1 score (macro): {cv_f1:.4f}\")\n",
    "    else:\n",
    "        print(f\"Cross-validation F1 score (macro): N/A\")\n",
    "\n",
    "    # Generate predictions on test set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Compute comprehensive metrics\n",
    "    metrics = compute_metrics_multiclass(y_test, y_pred)\n",
    "\n",
    "    # Generate and save confusion matrix visualization\n",
    "    cm = metrics[\"confusion_matrix\"]\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=class_labels, yticklabels=class_labels,\n",
    "                cbar_kws={'label': 'Count'})\n",
    "    plt.title(f\"{model_key.upper()} - Confusion Matrix (Multiclass)\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    cm_path = os.path.join(MODEL_DIR, f\"{model_key}_confusion_matrix.png\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(cm_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Visualizations saved for {model_key}\")\n",
    "\n",
    "    # Return summary metrics\n",
    "    return {\n",
    "        \"model\": model_key,\n",
    "        \"best_params\": str(best_params),\n",
    "        \"cv_f1_macro\": cv_f1,\n",
    "        \"test_accuracy\": metrics[\"accuracy\"],\n",
    "        \"test_precision_macro\": metrics[\"precision_macro\"],\n",
    "        \"test_recall_macro\": metrics[\"recall_macro\"],\n",
    "        \"test_f1_macro\": metrics[\"f1_macro\"],\n",
    "        \"test_f1_weighted\": metrics[\"f1_weighted\"]\n",
    "    }, best_model, y_pred, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bedd408",
   "metadata": {},
   "source": [
    "## 7. Main Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4de57a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results will be saved to: multiclass_classification\\results_20251201_141741\n",
      "\n",
      "\n",
      "============================================================\n",
      "Training LOG_REG\n",
      "============================================================\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best parameters: {'solver': 'lbfgs', 'penalty': 'l2', 'class_weight': None, 'C': 10}\n",
      "Cross-validation F1 score (macro): 0.7789\n",
      "Best parameters: {'solver': 'lbfgs', 'penalty': 'l2', 'class_weight': None, 'C': 10}\n",
      "Cross-validation F1 score (macro): 0.7789\n",
      "Visualizations saved for log_reg\n",
      "\n",
      "============================================================\n",
      "Training RF\n",
      "============================================================\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Visualizations saved for log_reg\n",
      "\n",
      "============================================================\n",
      "Training RF\n",
      "============================================================\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best parameters: {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 30, 'class_weight': None}\n",
      "Cross-validation F1 score (macro): 0.9546\n",
      "Best parameters: {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 30, 'class_weight': None}\n",
      "Cross-validation F1 score (macro): 0.9546\n",
      "Visualizations saved for rf\n",
      "\n",
      "============================================================\n",
      "Training LGB\n",
      "============================================================\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Visualizations saved for rf\n",
      "\n",
      "============================================================\n",
      "Training LGB\n",
      "============================================================\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best parameters: {'num_leaves': 40, 'n_estimators': 300, 'min_data_in_leaf': 30, 'max_depth': -1, 'learning_rate': 0.1, 'feature_fraction': 1.0, 'bagging_fraction': 0.8}\n",
      "Cross-validation F1 score (macro): 0.9625\n",
      "Best parameters: {'num_leaves': 40, 'n_estimators': 300, 'min_data_in_leaf': 30, 'max_depth': -1, 'learning_rate': 0.1, 'feature_fraction': 1.0, 'bagging_fraction': 0.8}\n",
      "Cross-validation F1 score (macro): 0.9625\n",
      "Visualizations saved for lgb\n",
      "\n",
      "============================================================\n",
      "Training MLP\n",
      "============================================================\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Visualizations saved for lgb\n",
      "\n",
      "============================================================\n",
      "Training MLP\n",
      "============================================================\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best parameters: {'learning_rate': 'adaptive', 'hidden_layer_sizes': (128, 64), 'batch_size': 64, 'alpha': 0.001, 'activation': 'tanh'}\n",
      "Cross-validation F1 score (macro): 0.9237\n",
      "Best parameters: {'learning_rate': 'adaptive', 'hidden_layer_sizes': (128, 64), 'batch_size': 64, 'alpha': 0.001, 'activation': 'tanh'}\n",
      "Cross-validation F1 score (macro): 0.9237\n",
      "Visualizations saved for mlp\n",
      "\n",
      "============================================================\n",
      "Training KNN\n",
      "============================================================\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Visualizations saved for mlp\n",
      "\n",
      "============================================================\n",
      "Training KNN\n",
      "============================================================\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best parameters: {'weights': 'distance', 'n_neighbors': 7, 'metric': 'manhattan'}\n",
      "Cross-validation F1 score (macro): 0.9219\n",
      "Best parameters: {'weights': 'distance', 'n_neighbors': 7, 'metric': 'manhattan'}\n",
      "Cross-validation F1 score (macro): 0.9219\n",
      "Visualizations saved for knn\n",
      "\n",
      "============================================================\n",
      "Training NB\n",
      "============================================================\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Visualizations saved for knn\n",
      "\n",
      "============================================================\n",
      "Training NB\n",
      "============================================================\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\burakdogan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 5 is smaller than n_iter=10. Running 5 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'var_smoothing': np.float64(1e-06)}\n",
      "Cross-validation F1 score (macro): 0.4793\n",
      "Visualizations saved for nb\n",
      "\n",
      "============================================================\n",
      "MODEL TRAINING COMPLETED SUCCESSFULLY\n",
      "============================================================\n",
      "\n",
      "Metrics summary saved: multiclass_classification\\results_20251201_141741\\01_metrics_summary_all_models.csv\n",
      "\n",
      "Visualizations saved for nb\n",
      "\n",
      "============================================================\n",
      "MODEL TRAINING COMPLETED SUCCESSFULLY\n",
      "============================================================\n",
      "\n",
      "Metrics summary saved: multiclass_classification\\results_20251201_141741\\01_metrics_summary_all_models.csv\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_params</th>\n",
       "      <th>cv_f1_macro</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_f1_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>log_reg</td>\n",
       "      <td>{'solver': 'lbfgs', 'penalty': 'l2', 'class_we...</td>\n",
       "      <td>0.778859</td>\n",
       "      <td>0.828228</td>\n",
       "      <td>0.811101</td>\n",
       "      <td>0.760782</td>\n",
       "      <td>0.781156</td>\n",
       "      <td>0.825236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rf</td>\n",
       "      <td>{'n_estimators': 100, 'min_samples_split': 2, ...</td>\n",
       "      <td>0.954619</td>\n",
       "      <td>0.965649</td>\n",
       "      <td>0.979563</td>\n",
       "      <td>0.941909</td>\n",
       "      <td>0.959610</td>\n",
       "      <td>0.965625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lgb</td>\n",
       "      <td>{'num_leaves': 40, 'n_estimators': 300, 'min_d...</td>\n",
       "      <td>0.962492</td>\n",
       "      <td>0.970825</td>\n",
       "      <td>0.985188</td>\n",
       "      <td>0.948098</td>\n",
       "      <td>0.965598</td>\n",
       "      <td>0.970829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mlp</td>\n",
       "      <td>{'learning_rate': 'adaptive', 'hidden_layer_si...</td>\n",
       "      <td>0.923675</td>\n",
       "      <td>0.946439</td>\n",
       "      <td>0.947728</td>\n",
       "      <td>0.917727</td>\n",
       "      <td>0.931908</td>\n",
       "      <td>0.946195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>knn</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 7, 'met...</td>\n",
       "      <td>0.921918</td>\n",
       "      <td>0.950702</td>\n",
       "      <td>0.952550</td>\n",
       "      <td>0.910649</td>\n",
       "      <td>0.929522</td>\n",
       "      <td>0.950382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nb</td>\n",
       "      <td>{'var_smoothing': np.float64(1e-06)}</td>\n",
       "      <td>0.479339</td>\n",
       "      <td>0.510719</td>\n",
       "      <td>0.534570</td>\n",
       "      <td>0.597409</td>\n",
       "      <td>0.476897</td>\n",
       "      <td>0.549873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model                                        best_params  cv_f1_macro  \\\n",
       "0  log_reg  {'solver': 'lbfgs', 'penalty': 'l2', 'class_we...     0.778859   \n",
       "1       rf  {'n_estimators': 100, 'min_samples_split': 2, ...     0.954619   \n",
       "2      lgb  {'num_leaves': 40, 'n_estimators': 300, 'min_d...     0.962492   \n",
       "3      mlp  {'learning_rate': 'adaptive', 'hidden_layer_si...     0.923675   \n",
       "4      knn  {'weights': 'distance', 'n_neighbors': 7, 'met...     0.921918   \n",
       "5       nb               {'var_smoothing': np.float64(1e-06)}     0.479339   \n",
       "\n",
       "   test_accuracy  test_precision_macro  test_recall_macro  test_f1_macro  \\\n",
       "0       0.828228              0.811101           0.760782       0.781156   \n",
       "1       0.965649              0.979563           0.941909       0.959610   \n",
       "2       0.970825              0.985188           0.948098       0.965598   \n",
       "3       0.946439              0.947728           0.917727       0.931908   \n",
       "4       0.950702              0.952550           0.910649       0.929522   \n",
       "5       0.510719              0.534570           0.597409       0.476897   \n",
       "\n",
       "   test_f1_weighted  \n",
       "0          0.825236  \n",
       "1          0.965625  \n",
       "2          0.970829  \n",
       "3          0.946195  \n",
       "4          0.950382  \n",
       "5          0.549873  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BEST MODEL: LGB\n",
      "Test F1-Score (Macro): 0.9656\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract class labels for visualization\n",
    "class_labels = sorted(y_train.unique())\n",
    "\n",
    "# Generate timestamp for unique results directory\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "RUN_DIR = os.path.join(\"multiclass_classification\", f\"results_{timestamp}\")\n",
    "os.makedirs(RUN_DIR, exist_ok=True)\n",
    "print(f\"Results will be saved to: {RUN_DIR}\\n\")\n",
    "\n",
    "results_list = []\n",
    "models_dict = {}\n",
    "y_preds_dict = {}\n",
    "metrics_dict = {}\n",
    "\n",
    "# Train all models using optimized RandomizedSearchCV\n",
    "for key in MODELS_TO_RUN:\n",
    "    result_row, best_model, y_pred, metrics = train_and_evaluate_model(\n",
    "        model_key=key,\n",
    "        model_def=model_defs[key],\n",
    "        X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test,\n",
    "        base_dir=RUN_DIR,\n",
    "        cv_folds=3,\n",
    "        n_iter=10,\n",
    "        class_labels=class_labels\n",
    "    )\n",
    "    results_list.append(result_row)\n",
    "    models_dict[key] = best_model\n",
    "    y_preds_dict[key] = y_pred\n",
    "    metrics_dict[key] = metrics\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"MODEL TRAINING COMPLETED SUCCESSFULLY\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Create metrics summary dataframe\n",
    "metrics_df = pd.DataFrame(results_list)\n",
    "metrics_csv = os.path.join(RUN_DIR, \"01_metrics_summary_all_models.csv\")\n",
    "metrics_df.to_csv(metrics_csv, index=False)\n",
    "print(f\"Metrics summary saved: {metrics_csv}\\n\")\n",
    "display(metrics_df)\n",
    "\n",
    "# Identify best performing model based on F1-macro\n",
    "best_model_key = metrics_df.loc[metrics_df[\"test_f1_macro\"].idxmax(), \"model\"]\n",
    "best_model_f1 = metrics_df.loc[metrics_df[\"test_f1_macro\"].idxmax(), \"test_f1_macro\"]\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"BEST MODEL: {best_model_key.upper()}\")\n",
    "print(f\"Test F1-Score (Macro): {best_model_f1:.4f}\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb51f8ad",
   "metadata": {},
   "source": [
    "## 8. Best Model Detailed Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "945005ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved: multiclass_classification\\results_20251201_141741\\best_multiclass_model_lgb.pkl\n",
      "\n",
      "Best model also saved to production: data\\models\\best_multiclass_attack_classification_model.pkl\n",
      "\n",
      "Best model also saved to production: data\\models\\best_multiclass_attack_classification_model.pkl\n",
      "\n",
      "Best model report generated and saved\n",
      "\n",
      "======================================================================\n",
      "MULTICLASS ATTACK CLASSIFICATION - BEST MODEL REPORT\n",
      "======================================================================\n",
      "\n",
      "Execution Timestamp: 20251201_141741\n",
      "Best Model: LGB\n",
      "Results Location: multiclass_classification\\results_20251201_141741\\best_multiclass_model_lgb.pkl\n",
      "Production Location: data\\models\\best_multiclass_attack_classification_model.pkl\n",
      "Attack Classes: bruteforce, ddos, dos, malware, mitm, recon, web\n",
      "Total Classes: 7\n",
      "\n",
      "======================================================================\n",
      "MODEL PERFORMANCE METRICS\n",
      "======================================================================\n",
      "\n",
      "Accuracy (overall):         0.9708\n",
      "Precision (macro):          0.9852\n",
      "Recall (macro):             0.9481\n",
      "F1-Score (macro):           0.9656\n",
      "F1-Score (weighted):        0.9708\n",
      "\n",
      "Confusion Matrix Shape: (7, 7)\n",
      "\n",
      "======================================================================\n",
      "CLASSIFICATION REPORT\n",
      "======================================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  bruteforce     0.9925    0.8811    0.9335      1203\n",
      "        ddos     0.9924    0.9434    0.9673     11339\n",
      "         dos     0.9939    0.9718    0.9827     11547\n",
      "     malware     0.9932    0.9686    0.9807      4835\n",
      "        mitm     0.9867    0.9614    0.9739      5098\n",
      "       recon     0.9376    0.9979    0.9668     21170\n",
      "         web     1.0000    0.9126    0.9543      1808\n",
      "\n",
      "    accuracy                         0.9708     57000\n",
      "   macro avg     0.9852    0.9481    0.9656     57000\n",
      "weighted avg     0.9721    0.9708    0.9708     57000\n",
      "\n",
      "\n",
      "======================================================================\n",
      "BEST MODEL HYPERPARAMETERS\n",
      "======================================================================\n",
      "\n",
      "{'n_estimators': [100, 200, 300], 'max_depth': [5, 10, 15, -1], 'learning_rate': [0.01, 0.05, 0.1], 'num_leaves': [20, 30, 40, 50], 'min_data_in_leaf': [10, 20, 30], 'feature_fraction': [0.8, 0.9, 1.0], 'bagging_fraction': [0.8, 0.9, 1.0]}\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Best model report generated and saved\n",
      "\n",
      "======================================================================\n",
      "MULTICLASS ATTACK CLASSIFICATION - BEST MODEL REPORT\n",
      "======================================================================\n",
      "\n",
      "Execution Timestamp: 20251201_141741\n",
      "Best Model: LGB\n",
      "Results Location: multiclass_classification\\results_20251201_141741\\best_multiclass_model_lgb.pkl\n",
      "Production Location: data\\models\\best_multiclass_attack_classification_model.pkl\n",
      "Attack Classes: bruteforce, ddos, dos, malware, mitm, recon, web\n",
      "Total Classes: 7\n",
      "\n",
      "======================================================================\n",
      "MODEL PERFORMANCE METRICS\n",
      "======================================================================\n",
      "\n",
      "Accuracy (overall):         0.9708\n",
      "Precision (macro):          0.9852\n",
      "Recall (macro):             0.9481\n",
      "F1-Score (macro):           0.9656\n",
      "F1-Score (weighted):        0.9708\n",
      "\n",
      "Confusion Matrix Shape: (7, 7)\n",
      "\n",
      "======================================================================\n",
      "CLASSIFICATION REPORT\n",
      "======================================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  bruteforce     0.9925    0.8811    0.9335      1203\n",
      "        ddos     0.9924    0.9434    0.9673     11339\n",
      "         dos     0.9939    0.9718    0.9827     11547\n",
      "     malware     0.9932    0.9686    0.9807      4835\n",
      "        mitm     0.9867    0.9614    0.9739      5098\n",
      "       recon     0.9376    0.9979    0.9668     21170\n",
      "         web     1.0000    0.9126    0.9543      1808\n",
      "\n",
      "    accuracy                         0.9708     57000\n",
      "   macro avg     0.9852    0.9481    0.9656     57000\n",
      "weighted avg     0.9721    0.9708    0.9708     57000\n",
      "\n",
      "\n",
      "======================================================================\n",
      "BEST MODEL HYPERPARAMETERS\n",
      "======================================================================\n",
      "\n",
      "{'n_estimators': [100, 200, 300], 'max_depth': [5, 10, 15, -1], 'learning_rate': [0.01, 0.05, 0.1], 'num_leaves': [20, 30, 40, 50], 'min_data_in_leaf': [10, 20, 30], 'feature_fraction': [0.8, 0.9, 1.0], 'bagging_fraction': [0.8, 0.9, 1.0]}\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract best model results\n",
    "best_model_obj = models_dict[best_model_key]\n",
    "y_pred_best = y_preds_dict[best_model_key]\n",
    "metrics_best = metrics_dict[best_model_key]\n",
    "\n",
    "# Save best model to its results directory\n",
    "best_model_path = os.path.join(RUN_DIR, f\"best_multiclass_model_{best_model_key}.pkl\")\n",
    "joblib.dump(best_model_obj, best_model_path)\n",
    "print(f\"Best model saved: {best_model_path}\\n\")\n",
    "\n",
    "# Also save to production directory for deployment\n",
    "best_model_prod_path = os.path.join(MODELS_DIR, f\"best_multiclass_attack_classification_model.pkl\")\n",
    "joblib.dump(best_model_obj, best_model_prod_path)\n",
    "print(f\"Best model also saved to production: {best_model_prod_path}\\n\")\n",
    "\n",
    "# Generate classification report for best model\n",
    "class_report = classification_report(y_test, y_pred_best,\n",
    "                                     target_names=class_labels,\n",
    "                                     digits=4)\n",
    "\n",
    "# Create detailed report text\n",
    "report_text = f\"\"\"\n",
    "{'='*70}\n",
    "MULTICLASS ATTACK CLASSIFICATION - BEST MODEL REPORT\n",
    "{'='*70}\n",
    "\n",
    "Execution Timestamp: {timestamp}\n",
    "Best Model: {best_model_key.upper()}\n",
    "Results Location: {best_model_path}\n",
    "Production Location: {best_model_prod_path}\n",
    "Attack Classes: {', '.join(class_labels)}\n",
    "Total Classes: {len(class_labels)}\n",
    "\n",
    "{'='*70}\n",
    "MODEL PERFORMANCE METRICS\n",
    "{'='*70}\n",
    "\n",
    "Accuracy (overall):         {metrics_best['accuracy']:.4f}\n",
    "Precision (macro):          {metrics_best['precision_macro']:.4f}\n",
    "Recall (macro):             {metrics_best['recall_macro']:.4f}\n",
    "F1-Score (macro):           {metrics_best['f1_macro']:.4f}\n",
    "F1-Score (weighted):        {metrics_best['f1_weighted']:.4f}\n",
    "\n",
    "Confusion Matrix Shape: {metrics_best['confusion_matrix'].shape}\n",
    "\n",
    "{'='*70}\n",
    "CLASSIFICATION REPORT\n",
    "{'='*70}\n",
    "\n",
    "{class_report}\n",
    "\n",
    "{'='*70}\n",
    "BEST MODEL HYPERPARAMETERS\n",
    "{'='*70}\n",
    "\n",
    "{str(model_defs[best_model_key]['param_grid'])}\n",
    "\n",
    "{'='*70}\n",
    "\"\"\"\n",
    "\n",
    "# Save report to file\n",
    "report_path = os.path.join(RUN_DIR, \"02_best_model_report.txt\")\n",
    "with open(report_path, \"w\") as f:\n",
    "    f.write(report_text)\n",
    "\n",
    "print(\"Best model report generated and saved\")\n",
    "print(report_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dadaeb5",
   "metadata": {},
   "source": [
    "## 9. Model Comparison Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c016ba93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: models_comparison_metrics.png\n",
      "Saved: f1_score_ranking.png\n",
      "Saved: f1_score_ranking.png\n",
      "Saved: metrics_heatmap.png\n",
      "\n",
      "All comparison visualizations generated successfully\n",
      "Saved: metrics_heatmap.png\n",
      "\n",
      "All comparison visualizations generated successfully\n"
     ]
    }
   ],
   "source": [
    "# 1. Performance metrics comparison across models\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "fig.suptitle(\"Multiclass Model Performance Comparison\", fontsize=16, fontweight='bold')\n",
    "\n",
    "metrics_to_plot = [\"test_accuracy\", \"test_precision_macro\", \"test_recall_macro\",\n",
    "                   \"test_f1_macro\", \"test_f1_weighted\", \"cv_f1_macro\"]\n",
    "colors = ['#FF6B6B' if model == best_model_key else '#4ECDC4'\n",
    "          for model in metrics_df[\"model\"]]\n",
    "\n",
    "for idx, metric in enumerate(metrics_to_plot):\n",
    "    ax = axes[idx // 3, idx % 3]\n",
    "    bars = ax.bar(metrics_df[\"model\"], metrics_df[metric], color=colors, alpha=0.8, edgecolor='black')\n",
    "    ax.set_ylabel(metric.replace(\"test_\", \"\").replace(\"_\", \" \"), fontsize=10)\n",
    "    ax.set_title(metric.replace(\"test_\", \"\").replace(\"_\", \" \").upper(), fontsize=11, fontweight='bold')\n",
    "    ax.set_ylim([0, 1.05])\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "comparison_path = os.path.join(RUN_DIR, \"03_models_comparison_metrics.png\")\n",
    "plt.savefig(comparison_path, dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"Saved: models_comparison_metrics.png\")\n",
    "\n",
    "# 2. F1-score ranking\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sorted_df = metrics_df.sort_values(\"test_f1_macro\", ascending=True)\n",
    "colors_rank = ['#FF6B6B' if model == best_model_key else '#95E1D3'\n",
    "               for model in sorted_df[\"model\"]]\n",
    "bars = ax.barh(sorted_df[\"model\"], sorted_df[\"test_f1_macro\"], color=colors_rank, edgecolor='black', alpha=0.85)\n",
    "\n",
    "ax.set_xlabel(\"F1-Score (Macro)\", fontsize=12)\n",
    "ax.set_title(\"Models Ranked by F1-Score (Macro)\", fontsize=14, fontweight='bold')\n",
    "ax.set_xlim([0, 1.05])\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "for idx, bar in enumerate(bars):\n",
    "    width = bar.get_width()\n",
    "    ax.text(width, bar.get_y() + bar.get_height()/2.,\n",
    "            f' {width:.4f}', ha='left', va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "ranking_path = os.path.join(RUN_DIR, \"04_f1_score_ranking.png\")\n",
    "plt.savefig(ranking_path, dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"Saved: f1_score_ranking.png\")\n",
    "\n",
    "# 3. Metrics heatmap\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "metrics_for_heatmap = metrics_df[[\n",
    "    \"model\", \"test_accuracy\", \"test_precision_macro\",\n",
    "    \"test_recall_macro\", \"test_f1_macro\", \"test_f1_weighted\"\n",
    "]].set_index(\"model\")\n",
    "sns.heatmap(metrics_for_heatmap.T, annot=True, fmt='.4f', cmap='RdYlGn',\n",
    "            cbar_kws={'label': 'Score'}, ax=ax, linewidths=0.5)\n",
    "ax.set_title(\"Multiclass Model Metrics Heatmap\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "heatmap_path = os.path.join(RUN_DIR, \"05_metrics_heatmap.png\")\n",
    "plt.savefig(heatmap_path, dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"Saved: metrics_heatmap.png\")\n",
    "\n",
    "print(\"\\nAll comparison visualizations generated successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75840e83",
   "metadata": {},
   "source": [
    "## 10. Execution Summary and Results Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01809fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RESULTS DIRECTORY STRUCTURE\n",
      "======================================================================\n",
      "\n",
      "results_20251201_141741/\n",
      "  01_metrics_summary_all_models.csv (1.4KB)\n",
      "  02_best_model_report.txt (2.1KB)\n",
      "  03_models_comparison_metrics.png (364.2KB)\n",
      "  04_f1_score_ranking.png (104.8KB)\n",
      "  05_metrics_heatmap.png (272.3KB)\n",
      "  best_multiclass_model_lgb.pkl (8771.9KB)\n",
      "  knn/\n",
      "    knn_confusion_matrix.png (236.2KB)\n",
      "  lgb/\n",
      "    lgb_confusion_matrix.png (220.4KB)\n",
      "  log_reg/\n",
      "    log_reg_confusion_matrix.png (256.9KB)\n",
      "  mlp/\n",
      "    mlp_confusion_matrix.png (234.6KB)\n",
      "  nb/\n",
      "    nb_confusion_matrix.png (243.2KB)\n",
      "  rf/\n",
      "    rf_confusion_matrix.png (219.4KB)\n",
      "\n",
      "======================================================================\n",
      "EXECUTION SUMMARY\n",
      "======================================================================\n",
      "\n",
      "\n",
      "MULTICLASS ATTACK CLASSIFICATION RESULTS\n",
      "\n",
      "Attack Classes: 7\n",
      "Attack Types: bruteforce, ddos, dos, malware, mitm, recon, web\n",
      "\n",
      "Total Models Trained: 6\n",
      "Models: LOG_REG, RF, LGB, MLP, KNN, NB\n",
      "\n",
      "Best Performing Model: LGB\n",
      "Best F1-Score (Macro): 0.9656\n",
      "\n",
      "Results Location: c:\\Users\\burakdogan\\Desktop\\Yapay Zeka Proje\\multiclass_classification\\results_20251201_141741\n",
      "\n",
      "Generated Files:\n",
      "- 01_metrics_summary_all_models.csv: Comprehensive metrics for all models\n",
      "- 02_best_model_report.txt: Detailed analysis of the best model\n",
      "- 03_models_comparison_metrics.png: Performance metrics comparison\n",
      "- 04_f1_score_ranking.png: Model ranking by F1-score\n",
      "- 05_metrics_heatmap.png: Metrics heatmap visualization\n",
      "\n",
      "Model-Specific Outputs:\n",
      "\n",
      "  LOG_REG:\n",
      "    - log_reg_confusion_matrix.png\n",
      "\n",
      "  RF:\n",
      "    - rf_confusion_matrix.png\n",
      "\n",
      "  LGB:\n",
      "    - lgb_confusion_matrix.png\n",
      "\n",
      "  MLP:\n",
      "    - mlp_confusion_matrix.png\n",
      "\n",
      "  KNN:\n",
      "    - knn_confusion_matrix.png\n",
      "\n",
      "  NB:\n",
      "    - nb_confusion_matrix.png\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Summary saved to: multiclass_classification\\results_20251201_141741\\00_EXECUTION_SUMMARY.txt\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*70}\")\n",
    "print(\"RESULTS DIRECTORY STRUCTURE\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# List all generated files in results directory\n",
    "for root, dirs, files in os.walk(RUN_DIR):\n",
    "    level = root.replace(RUN_DIR, '').count(os.sep)\n",
    "    indent = ' ' * 2 * level\n",
    "    print(f'{indent}{os.path.basename(root)}/')\n",
    "    sub_indent = ' ' * 2 * (level + 1)\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        file_size = os.path.getsize(file_path)\n",
    "        size_str = f\"{file_size / 1024:.1f}KB\" if file_size > 1024 else f\"{file_size}B\"\n",
    "        print(f'{sub_indent}{file} ({size_str})')\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"EXECUTION SUMMARY\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Generate execution summary\n",
    "summary_text = f\"\"\"\n",
    "MULTICLASS ATTACK CLASSIFICATION RESULTS\n",
    "\n",
    "Attack Classes: {len(class_labels)}\n",
    "Attack Types: {', '.join(class_labels)}\n",
    "\n",
    "Total Models Trained: {len(MODELS_TO_RUN)}\n",
    "Models: {', '.join([m.upper() for m in MODELS_TO_RUN])}\n",
    "\n",
    "Best Performing Model: {best_model_key.upper()}\n",
    "Best F1-Score (Macro): {best_model_f1:.4f}\n",
    "\n",
    "Results Location: {os.path.abspath(RUN_DIR)}\n",
    "\n",
    "Generated Files:\n",
    "- 01_metrics_summary_all_models.csv: Comprehensive metrics for all models\n",
    "- 02_best_model_report.txt: Detailed analysis of the best model\n",
    "- 03_models_comparison_metrics.png: Performance metrics comparison\n",
    "- 04_f1_score_ranking.png: Model ranking by F1-score\n",
    "- 05_metrics_heatmap.png: Metrics heatmap visualization\n",
    "\n",
    "Model-Specific Outputs:\n",
    "\"\"\"\n",
    "\n",
    "for model_key in MODELS_TO_RUN:\n",
    "    model_dir = os.path.join(RUN_DIR, model_key)\n",
    "    if os.path.exists(model_dir):\n",
    "        files = os.listdir(model_dir)\n",
    "        summary_text += f\"\\n  {model_key.upper()}:\\n\"\n",
    "        for file in sorted(files):\n",
    "            summary_text += f\"    - {file}\\n\"\n",
    "\n",
    "summary_text += f\"\"\"\n",
    "{'='*70}\n",
    "\"\"\"\n",
    "\n",
    "# Save summary to file\n",
    "summary_path = os.path.join(RUN_DIR, \"00_EXECUTION_SUMMARY.txt\")\n",
    "with open(summary_path, \"w\") as f:\n",
    "    f.write(summary_text)\n",
    "\n",
    "print(summary_text)\n",
    "print(f\"Summary saved to: {summary_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
