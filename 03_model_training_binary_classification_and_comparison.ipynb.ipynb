{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f73aa7c",
   "metadata": {},
   "source": [
    "### Binary Intrusion Detection â€” Model Training & Comparison\n",
    "\n",
    "This notebook performs binary classification (Attack vs Benign) on the engineered CIC-IIoT dataset `combined_engineered_features.csv`.\n",
    "Primary objective: train K-Nearest Neighbors (KNN).  \n",
    "Extended objective: train and compare multiple classifiers (KNN, Random Forest, SVM, Logistic Regression) with hyperparameter tuning, compute full set of metrics, plot ROC & confusion matrices, save best models and metric summary.\n",
    "\n",
    "**Notes:**\n",
    "- Input dataset path: `data/features/combined_engineered_features.csv`\n",
    "- Output models saved to: `data/models/`\n",
    "- Metric summary saved to: `data/models/metrics_summary.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605c146a",
   "metadata": {},
   "source": [
    "#### Imports & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93102fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve, confusion_matrix\n",
    ")\n",
    "import joblib\n",
    "sns.set(style=\"whitegrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Paths\n",
    "FEATURE_PATH = os.path.join(\"data\", \"features\", \"combined_engineered_features.csv\")\n",
    "MODELS_DIR = os.path.join(\"data\", \"models\")\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4617403",
   "metadata": {},
   "source": [
    "#### Load & Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adce377a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset: (685671, 45)\n",
      "Feature matrix shape: (685671, 40)\n",
      "Class distribution:\n",
      " label1\n",
      "Benign    400672\n",
      "Attack    284999\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell: load data\n",
    "df = pd.read_csv(FEATURE_PATH)\n",
    "print(\"Loaded dataset:\", df.shape)\n",
    "\n",
    "# Ensure label1 exists\n",
    "assert \"label1\" in df.columns, \"label1 column not found in dataset!\"\n",
    "\n",
    "# Prepare features and binary target\n",
    "X = df.drop(columns=[\"label1\",\"label2\",\"label3\",\"label4\",\"label_full\"], errors='ignore')\n",
    "y = df[\"label1\"].apply(lambda x: 1 if str(x).lower() == \"attack\" else 0)\n",
    "\n",
    "print(\"Feature matrix shape:\", X.shape)\n",
    "print(\"Class distribution:\\n\", y.value_counts().rename({0:\"Benign\",1:\"Attack\"}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2c8d9e",
   "metadata": {},
   "source": [
    "#### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97979a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (548536, 40) Test shape: (137135, 40)\n"
     ]
    }
   ],
   "source": [
    "RANDOM_STATE = 42\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ed4cd0",
   "metadata": {},
   "source": [
    "#### Evaluate model (metrics + plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdcc5f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: helper functions\n",
    "def compute_metrics(y_true, y_pred, y_prob=None):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, zero_division=0)  # sensitivity\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    spec = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "    roc_auc = roc_auc_score(y_true, y_prob) if (y_prob is not None) else np.nan\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"specificity\": spec,\n",
    "        \"f1\": f1,\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"confusion_matrix\": cm\n",
    "    }\n",
    "\n",
    "def plot_confusion(cm, labels=[\"Benign\",\"Attack\"], title=\"Confusion Matrix\"):\n",
    "    plt.figure(figsize=(4,3))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Reds\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc(y_true, y_prob, label):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "    plt.plot(fpr, tpr, label=f\"{label} (AUC={auc:.3f})\")\n",
    "    return auc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68bd129",
   "metadata": {},
   "source": [
    "#### Define Models + Parameter Grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46b25248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models to run: ['knn', 'nb']\n"
     ]
    }
   ],
   "source": [
    "model_defs = {}\n",
    "\n",
    "model_defs[\"knn\"] = {\n",
    "    \"estimator\": KNeighborsClassifier(),\n",
    "    \"param_grid\": {\n",
    "        \"n_neighbors\": [3, 5, 7, 9, 11],\n",
    "        \"weights\": [\"uniform\", \"distance\"],\n",
    "        \"metric\": [\"euclidean\", \"manhattan\", \"minkowski\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "model_defs[\"nb\"] = {\n",
    "    \"estimator\": GaussianNB(),\n",
    "    \"param_grid\": {\n",
    "        \"var_smoothing\": np.logspace(-10, -6, 5)\n",
    "    }\n",
    "}\n",
    "\n",
    "MODELS_TO_RUN = [\"knn\", \"nb\"]\n",
    "\n",
    "print(f\"Models to run: {MODELS_TO_RUN}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e74533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model_key, model_def, X_train, X_test, y_train, y_test, base_dir, cv_folds=3, n_iter=5):\n",
    "    \"\"\"Train, evaluate and save results for a single model.\"\"\"\n",
    "    spec = model_def\n",
    "    estimator = spec[\"estimator\"]\n",
    "    param_grid = spec[\"param_grid\"]\n",
    "\n",
    "    MODEL_DIR = os.path.join(base_dir, model_key)\n",
    "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "    print(f\"\\n=== Training {model_key.upper()} ===\")\n",
    "\n",
    "    # --- Randomized SearchCV ---\n",
    "    cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=RANDOM_STATE)\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=n_iter,\n",
    "        scoring=\"f1\",\n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "        random_state=RANDOM_STATE,\n",
    "        verbose=1\n",
    "    )\n",
    "    search.fit(X_train, y_train)\n",
    "    best = search.best_estimator_\n",
    "\n",
    "    # --- Evaluate ---\n",
    "    y_pred = best.predict(X_test)\n",
    "    y_prob = best.predict_proba(X_test)[:, 1] if hasattr(best, \"predict_proba\") else best.decision_function(X_test)\n",
    "    metrics = compute_metrics(y_test, y_pred, y_prob)\n",
    "\n",
    "    # --- Save model ---\n",
    "    model_path = os.path.join(MODEL_DIR, f\"{model_key}_best_model.pkl\")\n",
    "    joblib.dump(best, model_path)\n",
    "\n",
    "    # --- Save confusion matrix ---\n",
    "    cm = metrics[\"confusion_matrix\"]\n",
    "    plt.figure(figsize=(4,3))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Reds\",\n",
    "                xticklabels=[\"Benign\",\"Attack\"], yticklabels=[\"Benign\",\"Attack\"])\n",
    "    plt.title(f\"{model_key.upper()} Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
    "    cm_path = os.path.join(MODEL_DIR, f\"{model_key}_confusion_matrix.png\")\n",
    "    plt.tight_layout(); plt.savefig(cm_path, dpi=300); plt.close()\n",
    "\n",
    "    # --- Save ROC curve ---\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "    plt.figure(figsize=(5,4))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f\"AUC={roc_auc:.3f}\")\n",
    "    plt.plot([0,1],[0,1],\"k--\", lw=1)\n",
    "    plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(f\"ROC - {model_key.upper()}\"); plt.legend(loc=\"lower right\")\n",
    "    roc_path = os.path.join(MODEL_DIR, f\"{model_key}_roc_curve.png\")\n",
    "    plt.tight_layout(); plt.savefig(roc_path, dpi=300); plt.close()\n",
    "\n",
    "    print(f\"Saved model, confusion matrix, and ROC for {model_key}\")\n",
    "\n",
    "    # --- Return summary row ---\n",
    "    return {\n",
    "        \"model\": model_key,\n",
    "        \"best_params\": search.best_params_,\n",
    "        \"cv_f1\": search.best_score_,\n",
    "        \"test_accuracy\": metrics[\"accuracy\"],\n",
    "        \"test_precision\": metrics[\"precision\"],\n",
    "        \"test_recall\": metrics[\"recall\"],\n",
    "        \"test_specificity\": metrics[\"specificity\"],\n",
    "        \"test_f1\": metrics[\"f1\"],\n",
    "        \"test_roc_auc\": metrics[\"roc_auc\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecb94cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results will be saved under: results\\model_results_20251024_175610\n",
      "\n",
      "=== Training KNN ===\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "k-fold cross-validation requires at least one train/test split by setting n_splits=2 or more, got n_splits=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m MODELS_TO_RUN:\n\u001b[1;32m----> 9\u001b[0m     result_row \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_defs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRUN_DIR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcv_folds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(result_row)\n\u001b[0;32m     19\u001b[0m metrics_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\n",
      "Cell \u001b[1;32mIn[22], line 13\u001b[0m, in \u001b[0;36mtrain_and_evaluate_model\u001b[1;34m(model_key, model_def, X_train, X_test, y_train, y_test, base_dir, cv_folds, n_iter)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== Training \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_key\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# --- Randomized SearchCV ---\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m cv \u001b[38;5;241m=\u001b[39m \u001b[43mStratifiedKFold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv_folds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRANDOM_STATE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[0;32m     15\u001b[0m     estimator,\n\u001b[0;32m     16\u001b[0m     param_distributions\u001b[38;5;241m=\u001b[39mparam_grid,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     23\u001b[0m )\n\u001b[0;32m     24\u001b[0m search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "File \u001b[1;32mc:\\Users\\burak.dogan.2\\Desktop\\New folder (2)\\venv\\lib\\site-packages\\sklearn\\model_selection\\_split.py:771\u001b[0m, in \u001b[0;36mStratifiedKFold.__init__\u001b[1;34m(self, n_splits, shuffle, random_state)\u001b[0m\n\u001b[0;32m    770\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m*\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 771\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_splits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\burak.dogan.2\\Desktop\\New folder (2)\\venv\\lib\\site-packages\\sklearn\\model_selection\\_split.py:355\u001b[0m, in \u001b[0;36m_BaseKFold.__init__\u001b[1;34m(self, n_splits, shuffle, random_state)\u001b[0m\n\u001b[0;32m    352\u001b[0m n_splits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_splits)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_splits \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    356\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk-fold cross-validation requires at least one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    357\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m train/test split by setting n_splits=2 or more,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    358\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m got n_splits=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits)\n\u001b[0;32m    359\u001b[0m     )\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(shuffle, \u001b[38;5;28mbool\u001b[39m):\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshuffle must be True or False; got \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(shuffle))\n",
      "\u001b[1;31mValueError\u001b[0m: k-fold cross-validation requires at least one train/test split by setting n_splits=2 or more, got n_splits=1."
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "RUN_DIR = os.path.join(\"results\", f\"model_results_{timestamp}\")\n",
    "os.makedirs(RUN_DIR, exist_ok=True)\n",
    "print(f\"Results will be saved under: {RUN_DIR}\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for key in MODELS_TO_RUN:\n",
    "    result_row = train_and_evaluate_model(\n",
    "        model_key=key,\n",
    "        model_def=model_defs[key],\n",
    "        X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test,\n",
    "        base_dir=RUN_DIR,\n",
    "        cv_folds=2,\n",
    "        n_iter=1\n",
    "    )\n",
    "    results.append(result_row)\n",
    "\n",
    "metrics_df = pd.DataFrame(results)\n",
    "metrics_csv = os.path.join(RUN_DIR, \"metrics_summary_all_models.csv\")\n",
    "metrics_df.to_csv(metrics_csv, index=False)\n",
    "print(f\"\\nMetrics summary saved: {metrics_csv}\")\n",
    "display(metrics_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
